[2025-03-27T04:20:06.944+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-03-27T04:20:06.969+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T04:20:06.979+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T04:20:06.981+0000] {taskinstance.py:2867} INFO - Starting attempt 3 of 6
[2025-03-27T04:20:07.000+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): scrape_and_store> on 2025-03-02 00:00:00+00:00
[2025-03-27T04:20:07.006+0000] {standard_task_runner.py:72} INFO - Started process 379 to run task
[2025-03-27T04:20:07.013+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'construction_web_scraping_v01', 'scrape_and_store', 'scheduled__2025-03-02T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/construction_web_scraping.py', '--cfg-path', '/tmp/tmp9k0ah3nw']
[2025-03-27T04:20:07.017+0000] {standard_task_runner.py:105} INFO - Job 15: Subtask scrape_and_store
[2025-03-27T04:20:07.085+0000] {task_command.py:467} INFO - Running <TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [running]> on host c79bd584e644
[2025-03-27T04:20:07.188+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='waiyong' AIRFLOW_CTX_DAG_ID='construction_web_scraping_v01' AIRFLOW_CTX_TASK_ID='scrape_and_store' AIRFLOW_CTX_EXECUTION_DATE='2025-03-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-02T00:00:00+00:00'
[2025-03-27T04:20:07.190+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-03-27T04:20:07.208+0000] {logging_mixin.py:190} INFO - Scraping page 1...
[2025-03-27T04:20:21.172+0000] {logging_mixin.py:190} INFO - Scraping page 2...
[2025-03-27T04:20:35.980+0000] {logging_mixin.py:190} INFO - Scraping page 3...
[2025-03-27T04:20:56.295+0000] {logging_mixin.py:190} INFO - Scraping page 4...
[2025-03-27T04:21:10.301+0000] {logging_mixin.py:190} INFO - Scraping page 5...
[2025-03-27T04:21:24.016+0000] {logging_mixin.py:190} INFO - Columns before rename: ['BIL.', 'KOD PROJEK', 'PEMAJU', 'PROJEK', 'NO. PERMIT', 'STATUS PROJEK KESELURUHAN', 'RINGKASAN PROJEK', 'Daerah Projek', 'Negeri Projek', 'Harga Minimum (RM)', 'Harga Maksimum (RM)']
[2025-03-27T04:21:24.057+0000] {logging_mixin.py:190} INFO -   Bil  ...                                  RINGKASAN PROJEK
0   1  ...  https://teduh.kpkt.gov.my/project-swasta/30969-1
1   2  ...  https://teduh.kpkt.gov.my/project-swasta/30946-1
2   3  ...  https://teduh.kpkt.gov.my/project-swasta/30937-1
3   4  ...  https://teduh.kpkt.gov.my/project-swasta/30921-1
4   5  ...  https://teduh.kpkt.gov.my/project-swasta/30920-1
5   6  ...  https://teduh.kpkt.gov.my/project-swasta/30914-1
6   7  ...  https://teduh.kpkt.gov.my/project-swasta/30913-1
7   8  ...  https://teduh.kpkt.gov.my/project-swasta/30909-1
8   9  ...  https://teduh.kpkt.gov.my/project-swasta/30908-1
9  10  ...  https://teduh.kpkt.gov.my/project-swasta/30902-1

[10 rows x 11 columns]
[2025-03-27T04:21:24.096+0000] {logging_mixin.py:190} INFO - SQL dump created: /tmp/teduh_dump.sql
[2025-03-27T04:21:24.097+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/construction_web_scraping.py", line 255, in run_scraper
    client = create_minio_client()
NameError: name 'create_minio_client' is not defined
[2025-03-27T04:21:24.111+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=construction_web_scraping_v01, task_id=scrape_and_store, run_id=scheduled__2025-03-02T00:00:00+00:00, execution_date=20250302T000000, start_date=20250327T042006, end_date=20250327T042124
[2025-03-27T04:21:24.143+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-03-27T04:21:24.144+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 15 for task scrape_and_store (name 'create_minio_client' is not defined; 379)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/construction_web_scraping.py", line 255, in run_scraper
    client = create_minio_client()
NameError: name 'create_minio_client' is not defined
[2025-03-27T04:21:24.169+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-03-27T04:21:24.191+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-03-27T04:21:24.194+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-03-27T04:40:05.973+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-03-27T04:40:05.997+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T04:40:06.010+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T04:40:06.012+0000] {taskinstance.py:2867} INFO - Starting attempt 3 of 8
[2025-03-27T04:40:06.031+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): scrape_and_store> on 2025-03-02 00:00:00+00:00
[2025-03-27T04:40:06.039+0000] {standard_task_runner.py:72} INFO - Started process 922 to run task
[2025-03-27T04:40:06.046+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'construction_web_scraping_v01', 'scrape_and_store', 'scheduled__2025-03-02T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/construction_web_scraping.py', '--cfg-path', '/tmp/tmpezmwo0ih']
[2025-03-27T04:40:06.050+0000] {standard_task_runner.py:105} INFO - Job 28: Subtask scrape_and_store
[2025-03-27T04:40:06.125+0000] {task_command.py:467} INFO - Running <TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [running]> on host c79bd584e644
[2025-03-27T04:40:06.253+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='waiyong' AIRFLOW_CTX_DAG_ID='construction_web_scraping_v01' AIRFLOW_CTX_TASK_ID='scrape_and_store' AIRFLOW_CTX_EXECUTION_DATE='2025-03-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-02T00:00:00+00:00'
[2025-03-27T04:40:06.256+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-03-27T04:40:06.279+0000] {logging_mixin.py:190} INFO - Scraping page 1...
[2025-03-27T04:40:21.418+0000] {logging_mixin.py:190} INFO - Columns before rename: ['BIL.', 'KOD PROJEK', 'PEMAJU', 'PROJEK', 'NO. PERMIT', 'STATUS PROJEK KESELURUHAN', 'RINGKASAN PROJEK', 'Daerah Projek', 'Negeri Projek', 'Harga Minimum (RM)', 'Harga Maksimum (RM)']
[2025-03-27T04:40:21.440+0000] {logging_mixin.py:190} INFO -   Bil  ...                                  RINGKASAN PROJEK
0   1  ...  https://teduh.kpkt.gov.my/project-swasta/30969-1
1   2  ...  https://teduh.kpkt.gov.my/project-swasta/30946-1
2   3  ...  https://teduh.kpkt.gov.my/project-swasta/30937-1
3   4  ...  https://teduh.kpkt.gov.my/project-swasta/30921-1
4   5  ...  https://teduh.kpkt.gov.my/project-swasta/30920-1
5   6  ...  https://teduh.kpkt.gov.my/project-swasta/30914-1
6   7  ...  https://teduh.kpkt.gov.my/project-swasta/30913-1
7   8  ...  https://teduh.kpkt.gov.my/project-swasta/30909-1
8   9  ...  https://teduh.kpkt.gov.my/project-swasta/30908-1
9  10  ...  https://teduh.kpkt.gov.my/project-swasta/30902-1

[10 rows x 11 columns]
[2025-03-27T04:40:21.471+0000] {logging_mixin.py:190} INFO - SQL dump created: /tmp/teduh_dump.sql
[2025-03-27T04:40:21.555+0000] {logging_mixin.py:190} INFO - Uploaded /tmp/teduh_dump.sql to minio://construction-web-scraping/teduh/temp.sql
[2025-03-27T04:40:21.557+0000] {logging_mixin.py:190} INFO - Scraping and upload done!
[2025-03-27T04:40:21.560+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-03-27T04:40:21.576+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-03-27T04:40:21.578+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=construction_web_scraping_v01, task_id=scrape_and_store, run_id=scheduled__2025-03-02T00:00:00+00:00, execution_date=20250302T000000, start_date=20250327T044005, end_date=20250327T044021
[2025-03-27T04:40:21.630+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-03-27T04:40:21.651+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-03-27T04:40:21.654+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-03-27T06:01:16.204+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-03-27T06:01:16.227+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T06:01:16.238+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T06:01:16.240+0000] {taskinstance.py:2867} INFO - Starting attempt 3 of 8
[2025-03-27T06:01:16.261+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): scrape_and_store> on 2025-03-02 00:00:00+00:00
[2025-03-27T06:01:16.267+0000] {standard_task_runner.py:72} INFO - Started process 2890 to run task
[2025-03-27T06:01:16.272+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'construction_web_scraping_v01', 'scrape_and_store', 'scheduled__2025-03-02T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/construction_web_scraping.py', '--cfg-path', '/tmp/tmp9evxjanp']
[2025-03-27T06:01:16.276+0000] {standard_task_runner.py:105} INFO - Job 37: Subtask scrape_and_store
[2025-03-27T06:01:16.337+0000] {task_command.py:467} INFO - Running <TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [running]> on host c79bd584e644
[2025-03-27T06:01:16.430+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='waiyong' AIRFLOW_CTX_DAG_ID='construction_web_scraping_v01' AIRFLOW_CTX_TASK_ID='scrape_and_store' AIRFLOW_CTX_EXECUTION_DATE='2025-03-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-02T00:00:00+00:00'
[2025-03-27T06:01:16.432+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-03-27T06:01:16.448+0000] {logging_mixin.py:190} INFO - Scraping page 1...
[2025-03-27T06:01:33.274+0000] {logging_mixin.py:190} INFO - Columns before rename: ['BIL.', 'KOD PROJEK', 'PEMAJU', 'PROJEK', 'NO. PERMIT', 'STATUS PROJEK KESELURUHAN', 'RINGKASAN PROJEK', 'Daerah Projek', 'Negeri Projek', 'Harga Minimum (RM)', 'Harga Maksimum (RM)']
[2025-03-27T06:01:33.295+0000] {logging_mixin.py:190} INFO -   Bil  ...                                  RINGKASAN PROJEK
0   1  ...  https://teduh.kpkt.gov.my/project-swasta/30969-1
1   2  ...  https://teduh.kpkt.gov.my/project-swasta/30946-1
2   3  ...  https://teduh.kpkt.gov.my/project-swasta/30937-1
3   4  ...  https://teduh.kpkt.gov.my/project-swasta/30921-1
4   5  ...  https://teduh.kpkt.gov.my/project-swasta/30920-1
5   6  ...  https://teduh.kpkt.gov.my/project-swasta/30914-1
6   7  ...  https://teduh.kpkt.gov.my/project-swasta/30913-1
7   8  ...  https://teduh.kpkt.gov.my/project-swasta/30909-1
8   9  ...  https://teduh.kpkt.gov.my/project-swasta/30908-1
9  10  ...  https://teduh.kpkt.gov.my/project-swasta/30902-1

[10 rows x 11 columns]
[2025-03-27T06:01:33.300+0000] {logging_mixin.py:190} INFO - CSV file created: /tmp/construction_20250327.csv
[2025-03-27T06:01:33.370+0000] {logging_mixin.py:190} INFO - Uploaded /tmp/construction_20250327.csv to minio://construction-web-scraping/teduh/teduh_dump.csv
[2025-03-27T06:01:33.371+0000] {logging_mixin.py:190} INFO - Scraping and upload done!
[2025-03-27T06:01:33.373+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-03-27T06:01:33.387+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-03-27T06:01:33.388+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=construction_web_scraping_v01, task_id=scrape_and_store, run_id=scheduled__2025-03-02T00:00:00+00:00, execution_date=20250302T000000, start_date=20250327T060116, end_date=20250327T060133
[2025-03-27T06:01:33.447+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-03-27T06:01:33.466+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-03-27T06:01:33.469+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-03-27T07:14:24.550+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-03-27T07:14:24.569+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T07:14:24.581+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [queued]>
[2025-03-27T07:14:24.582+0000] {taskinstance.py:2867} INFO - Starting attempt 3 of 6
[2025-03-27T07:14:24.599+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): scrape_and_store> on 2025-03-02 00:00:00+00:00
[2025-03-27T07:14:24.606+0000] {standard_task_runner.py:72} INFO - Started process 5266 to run task
[2025-03-27T07:14:24.610+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'construction_web_scraping_v01', 'scrape_and_store', 'scheduled__2025-03-02T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/construction_web_scraping.py', '--cfg-path', '/tmp/tmpw_akpp8i']
[2025-03-27T07:14:24.613+0000] {standard_task_runner.py:105} INFO - Job 64: Subtask scrape_and_store
[2025-03-27T07:14:24.670+0000] {task_command.py:467} INFO - Running <TaskInstance: construction_web_scraping_v01.scrape_and_store scheduled__2025-03-02T00:00:00+00:00 [running]> on host c79bd584e644
[2025-03-27T07:14:24.763+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='waiyong' AIRFLOW_CTX_DAG_ID='construction_web_scraping_v01' AIRFLOW_CTX_TASK_ID='scrape_and_store' AIRFLOW_CTX_EXECUTION_DATE='2025-03-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-02T00:00:00+00:00'
[2025-03-27T07:14:24.765+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-03-27T07:14:24.780+0000] {logging_mixin.py:190} INFO - Scraping page 1...
[2025-03-27T07:14:42.747+0000] {logging_mixin.py:190} INFO - Scraping page 2...
[2025-03-27T07:15:00.722+0000] {logging_mixin.py:190} INFO - Scraping page 3...
[2025-03-27T07:15:22.273+0000] {logging_mixin.py:190} INFO - Scraping page 4...
[2025-03-27T07:15:39.480+0000] {logging_mixin.py:190} INFO - Scraping page 5...
[2025-03-27T07:15:57.935+0000] {logging_mixin.py:190} INFO - Scraping page 6...
[2025-03-27T07:16:15.669+0000] {logging_mixin.py:190} INFO - Scraping page 7...
[2025-03-27T07:16:31.727+0000] {logging_mixin.py:190} INFO - Scraping page 8...
[2025-03-27T07:16:50.886+0000] {logging_mixin.py:190} INFO - Scraping page 9...
[2025-03-27T07:17:09.016+0000] {logging_mixin.py:190} INFO - Scraping page 10...
[2025-03-27T07:17:27.203+0000] {logging_mixin.py:190} INFO - Scraping page 11...
[2025-03-27T07:17:46.828+0000] {logging_mixin.py:190} INFO - Scraping page 12...
[2025-03-27T07:18:04.735+0000] {logging_mixin.py:190} INFO - Scraping page 13...
[2025-03-27T07:18:21.638+0000] {logging_mixin.py:190} INFO - Scraping page 14...
[2025-03-27T07:18:37.549+0000] {logging_mixin.py:190} INFO - Scraping page 15...
[2025-03-27T07:18:55.684+0000] {logging_mixin.py:190} INFO - Scraping page 16...
[2025-03-27T07:19:12.233+0000] {logging_mixin.py:190} INFO - Scraping page 17...
[2025-03-27T07:19:29.644+0000] {logging_mixin.py:190} INFO - Scraping page 18...
[2025-03-27T07:19:48.089+0000] {logging_mixin.py:190} INFO - Scraping page 19...
[2025-03-27T07:20:05.717+0000] {logging_mixin.py:190} INFO - Scraping page 20...
[2025-03-27T07:20:22.739+0000] {logging_mixin.py:190} INFO - Scraping page 21...
[2025-03-27T07:20:40.843+0000] {logging_mixin.py:190} INFO - Scraping page 22...
[2025-03-27T07:20:57.503+0000] {logging_mixin.py:190} INFO - Scraping page 23...
[2025-03-27T07:21:15.027+0000] {logging_mixin.py:190} INFO - Scraping page 24...
[2025-03-27T07:21:32.010+0000] {logging_mixin.py:190} INFO - Scraping page 25...
[2025-03-27T07:21:48.596+0000] {logging_mixin.py:190} INFO - Scraping page 26...
[2025-03-27T07:22:04.559+0000] {logging_mixin.py:190} INFO - Scraping page 27...
[2025-03-27T07:22:21.881+0000] {logging_mixin.py:190} INFO - Scraping page 28...
[2025-03-27T07:22:39.748+0000] {logging_mixin.py:190} INFO - Scraping page 29...
[2025-03-27T07:22:56.053+0000] {logging_mixin.py:190} INFO - Scraping page 30...
[2025-03-27T07:23:13.772+0000] {logging_mixin.py:190} INFO - Scraping page 31...
[2025-03-27T07:23:30.422+0000] {logging_mixin.py:190} INFO - Scraping page 32...
[2025-03-27T07:23:48.259+0000] {logging_mixin.py:190} INFO - Scraping page 33...
[2025-03-27T07:24:05.334+0000] {logging_mixin.py:190} INFO - Scraping page 34...
[2025-03-27T07:24:22.926+0000] {logging_mixin.py:190} INFO - Scraping page 35...
[2025-03-27T07:24:39.806+0000] {logging_mixin.py:190} INFO - Scraping page 36...
[2025-03-27T07:24:58.254+0000] {logging_mixin.py:190} INFO - Scraping page 37...
[2025-03-27T07:25:18.988+0000] {logging_mixin.py:190} INFO - Scraping page 38...
[2025-03-27T07:25:37.655+0000] {logging_mixin.py:190} INFO - Scraping page 39...
[2025-03-27T07:25:54.032+0000] {logging_mixin.py:190} INFO - Scraping page 40...
[2025-03-27T07:26:10.962+0000] {logging_mixin.py:190} INFO - Scraping page 41...
[2025-03-27T07:26:28.734+0000] {logging_mixin.py:190} INFO - Scraping page 42...
[2025-03-27T07:26:45.854+0000] {logging_mixin.py:190} INFO - Scraping page 43...
[2025-03-27T07:27:01.748+0000] {logging_mixin.py:190} INFO - Scraping page 44...
[2025-03-27T07:27:18.006+0000] {logging_mixin.py:190} INFO - Scraping page 45...
[2025-03-27T07:27:38.234+0000] {logging_mixin.py:190} INFO - Scraping page 46...
[2025-03-27T07:27:56.536+0000] {logging_mixin.py:190} INFO - Scraping page 47...
[2025-03-27T07:28:18.052+0000] {logging_mixin.py:190} INFO - Scraping page 48...
[2025-03-27T07:28:36.180+0000] {logging_mixin.py:190} INFO - Scraping page 49...
[2025-03-27T07:28:53.257+0000] {logging_mixin.py:190} INFO - Scraping page 50...
[2025-03-27T07:29:10.495+0000] {logging_mixin.py:190} INFO - Scraping page 51...
[2025-03-27T07:29:27.580+0000] {logging_mixin.py:190} INFO - Scraping page 52...
[2025-03-27T07:29:45.801+0000] {logging_mixin.py:190} INFO - Scraping page 53...
[2025-03-27T07:30:05.156+0000] {logging_mixin.py:190} INFO - Scraping page 54...
[2025-03-27T07:30:22.622+0000] {logging_mixin.py:190} INFO - Scraping page 55...
[2025-03-27T07:30:41.026+0000] {logging_mixin.py:190} INFO - Scraping page 56...
[2025-03-27T07:30:57.456+0000] {logging_mixin.py:190} INFO - Scraping page 57...
[2025-03-27T07:31:18.093+0000] {logging_mixin.py:190} INFO - Scraping page 58...
[2025-03-27T07:31:35.498+0000] {logging_mixin.py:190} INFO - Scraping page 59...
[2025-03-27T07:31:53.866+0000] {logging_mixin.py:190} INFO - Scraping page 60...
[2025-03-27T07:32:09.718+0000] {logging_mixin.py:190} INFO - Scraping page 61...
[2025-03-27T07:32:27.446+0000] {logging_mixin.py:190} INFO - Scraping page 62...
[2025-03-27T07:32:45.676+0000] {logging_mixin.py:190} INFO - Scraping page 63...
[2025-03-27T07:33:05.116+0000] {logging_mixin.py:190} INFO - Scraping page 64...
[2025-03-27T07:33:22.611+0000] {logging_mixin.py:190} INFO - Scraping page 65...
[2025-03-27T07:33:39.803+0000] {logging_mixin.py:190} INFO - Scraping page 66...
[2025-03-27T07:33:56.262+0000] {logging_mixin.py:190} INFO - Scraping page 67...
[2025-03-27T07:34:13.782+0000] {logging_mixin.py:190} INFO - Scraping page 68...
[2025-03-27T07:34:31.539+0000] {logging_mixin.py:190} INFO - Scraping page 69...
[2025-03-27T07:34:48.915+0000] {logging_mixin.py:190} INFO - Scraping page 70...
[2025-03-27T07:35:06.472+0000] {logging_mixin.py:190} INFO - Scraping page 71...
[2025-03-27T07:35:23.001+0000] {logging_mixin.py:190} INFO - Scraping page 72...
[2025-03-27T07:35:42.813+0000] {logging_mixin.py:190} INFO - Scraping page 73...
[2025-03-27T07:36:00.214+0000] {logging_mixin.py:190} INFO - Scraping page 74...
[2025-03-27T07:36:17.268+0000] {logging_mixin.py:190} INFO - Scraping page 75...
[2025-03-27T07:36:33.966+0000] {logging_mixin.py:190} INFO - Scraping page 76...
[2025-03-27T07:36:50.892+0000] {logging_mixin.py:190} INFO - Scraping page 77...
[2025-03-27T07:37:10.197+0000] {logging_mixin.py:190} INFO - Scraping page 78...
[2025-03-27T07:37:28.004+0000] {logging_mixin.py:190} INFO - Scraping page 79...
[2025-03-27T07:37:44.800+0000] {logging_mixin.py:190} INFO - Scraping page 80...
[2025-03-27T07:38:02.257+0000] {logging_mixin.py:190} INFO - Scraping page 81...
[2025-03-27T07:38:19.730+0000] {logging_mixin.py:190} INFO - Scraping page 82...
[2025-03-27T07:38:37.184+0000] {logging_mixin.py:190} INFO - Scraping page 83...
[2025-03-27T07:38:53.617+0000] {logging_mixin.py:190} INFO - Scraping page 84...
[2025-03-27T07:39:11.162+0000] {logging_mixin.py:190} INFO - Scraping page 85...
[2025-03-27T07:39:28.425+0000] {logging_mixin.py:190} INFO - Scraping page 86...
[2025-03-27T07:39:46.713+0000] {logging_mixin.py:190} INFO - Scraping page 87...
[2025-03-27T07:40:05.293+0000] {logging_mixin.py:190} INFO - Scraping page 88...
[2025-03-27T07:40:24.559+0000] {logging_mixin.py:190} INFO - Scraping page 89...
[2025-03-27T07:40:43.862+0000] {logging_mixin.py:190} INFO - Scraping page 90...
[2025-03-27T07:41:00.866+0000] {logging_mixin.py:190} INFO - Scraping page 91...
[2025-03-27T07:41:20.223+0000] {logging_mixin.py:190} INFO - Scraping page 92...
[2025-03-27T07:41:37.057+0000] {logging_mixin.py:190} INFO - Scraping page 93...
[2025-03-27T07:41:55.244+0000] {logging_mixin.py:190} INFO - Scraping page 94...
[2025-03-27T07:42:12.468+0000] {logging_mixin.py:190} INFO - Scraping page 95...
[2025-03-27T07:42:30.426+0000] {logging_mixin.py:190} INFO - Scraping page 96...
[2025-03-27T07:42:49.829+0000] {logging_mixin.py:190} INFO - Scraping page 97...
[2025-03-27T07:43:05.987+0000] {logging_mixin.py:190} INFO - Scraping page 98...
[2025-03-27T07:43:24.642+0000] {logging_mixin.py:190} INFO - Scraping page 99...
[2025-03-27T07:43:43.587+0000] {logging_mixin.py:190} INFO - Scraping page 100...
[2025-03-27T07:44:00.586+0000] {logging_mixin.py:190} INFO - Scraping page 101...
[2025-03-27T07:44:18.113+0000] {logging_mixin.py:190} INFO - Scraping page 102...
[2025-03-27T07:44:24.645+0000] {timeout.py:68} ERROR - Process timed out, PID: 5266
[2025-03-27T07:44:24.655+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 763, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/construction_web_scraping.py", line 183, in run_scraper
    daerah, negeri, harga_min, harga_maks = scrape_additional_data(link)
  File "/opt/airflow/dags/construction_web_scraping.py", line 49, in scrape_additional_data
    soup = BeautifulSoup(response.content, 'html.parser')
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/__init__.py", line 473, in __init__
    self._feed()
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/__init__.py", line 658, in _feed
    self.builder.feed(self.markup)
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py", line 467, in feed
    parser.feed(markup)
  File "/usr/local/lib/python3.10/html/parser.py", line 110, in feed
    self.goahead(0)
  File "/usr/local/lib/python3.10/html/parser.py", line 172, in goahead
    k = self.parse_endtag(i)
  File "/usr/local/lib/python3.10/html/parser.py", line 420, in parse_endtag
    self.handle_endtag(elem)
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py", line 220, in handle_endtag
    self.soup.handle_endtag(name)
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/__init__.py", line 1062, in handle_endtag
    self.endData()
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/__init__.py", line 864, in endData
    o = containerClass(current_data)
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/element.py", line 1304, in __new__
    u.setup()
  File "/home/airflow/.local/lib/python3.10/site-packages/bs4/element.py", line 404, in setup
    if self.previous_element is not None:
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout, PID: 5266
[2025-03-27T07:44:24.678+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=construction_web_scraping_v01, task_id=scrape_and_store, run_id=scheduled__2025-03-02T00:00:00+00:00, execution_date=20250302T000000, start_date=20250327T071424, end_date=20250327T074424
[2025-03-27T07:44:24.734+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-03-27T07:44:24.780+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 2
[2025-03-27T07:44:24.814+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-03-27T07:44:24.817+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
